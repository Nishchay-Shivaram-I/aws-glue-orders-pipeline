# AWS Glue Data Lake Pipeline â€“ Orders Analytics

This project builds a real-time data pipeline using AWS Glue, S3, and PySpark. It follows the Bronzeâ€“Silverâ€“Gold architecture pattern to ingest, clean, and aggregate order data from CSV to analytics-ready formats.

## ğŸ› ï¸ Tools Used
- AWS S3
- AWS Glue Studio (Spark)
- PySpark (via Glue)
- IAM roles
- Python 3

## ğŸ§± Pipeline Architecture

Raw CSV (S3: /raw/orders.csv)
â†“ [bronze_ingest.py]
Bronze Layer (Parquet: /bronze/orders_bronze/)
â†“ [silver_clean.py]
Silver Layer (Typed: /silver/orders_silver/)
â†“ [gold_aggregate.py]
Gold Layer (Aggregated: /gold/daily_sales/)


## ğŸ“‚ Folder Structure

aws-glue-orders-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ bronze_ingest.py
â”‚ â”œâ”€â”€ silver_clean.py
â”‚ â””â”€â”€ gold_aggregate.py


## ğŸ” Description of ETL Jobs

### 1. `bronze_ingest.py`
Ingests raw `orders.csv` from S3 and stores it as Parquet in the Bronze layer.

### 2. `silver_clean.py`
Cleans and typecasts the Bronze data into structured columns like `order_id`, `amount`, and `order_date`.

### 3. `gold_aggregate.py`
Aggregates daily sales totals and writes results to the Gold layer.

## âœ… Output Example

| order_date | total_sales |
|------------|-------------|
| 2023-08-01 | 220.49      |
| 2023-08-02 | 350.00      |
| 2023-08-03 | 80.00       |

## ğŸ’¡ Future Improvements

- Query with Athena
- Visualize in QuickSight
- Add data quality checks
- Schedule with Glue Workflows

---

## ğŸ‘¤ Author

**Nishchay S**  
[GitHub Profile](https://github.com/Nishchay-Shivaram-I)

---

## ğŸ“œ License

MIT â€“ do whatever you want ğŸ˜

